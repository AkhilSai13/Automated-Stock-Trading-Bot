{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhilSai13/Automated-Stock-Trading-Bot/blob/main/LSTM_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88N5g6KANjGi"
      },
      "outputs": [],
      "source": [
        "import yfinance as y\n",
        "symbol_list = [\"ADANIENT.NS\", \"ADANIPORTS.NS\", \"APOLLOHOSP.NS\", \"ASIANPAINT.NS\", \"AXISBANK.NS\", \"BAJAJ-AUTO.NS\", \"BAJAJFINSV.NS\", \"BHARTIARTL.NS\", \"BPCL.NS\", \"BRITANNIA.NS\", \"CIPLA.NS\", \"COALINDIA.NS\", \"DIVISLAB.NS\", \"DRREDDY.NS\", \"EICHERMOT.NS\", \"GRASIM.NS\", \"HCLTECH.NS\", \"HDFC.NS\", \"HDFCBANK.NS\", \"HDFCLIFE.NS\", \"HEROMOTOCO.NS\", \"HINDALCO.NS\", \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"INDUSINDBK.NS\", \"INFY.NS\", \"ITC.NS\", \"JSWSTEEL.NS\", \"KOTAKBANK.NS\", \"LT.NS\", \"M&M.NS\", \"NTPC.NS\", \"ONGC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\", \"SBILIFE.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\", \"TATACONSUM.NS\", \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TCS.NS\", \"TECHM.NS\", \"TITAN.NS\", \"UPL.NS\", \"WIPRO.NS\"]\n",
        "#symbol_list = [\"TCS.NS\", \"WIPRO.NS\", \"ICICIBANK.NS\", \"NESTLEIND.NS\", \"RELIANCE.NS\"]\n",
        "datef = {}\n",
        "rmse_dict = dict()\n",
        "tp_d = {}\n",
        "fp_d = {}\n",
        "fn_d = {}\n",
        "tn_d = {}\n",
        "\n",
        "for j in symbol_list:\n",
        "  dataset1 = y.download( j, start = '2012-01-02', end = '2023-03-31')\n",
        "  temp1= y.download( j, start = '2012-01-02', end = '2019-12-31')\n",
        "\n",
        "  tpg = fpg = fng = tng = 0\n",
        "  dates = []\n",
        "  rmset = []\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "    dataset = dataset1[i::5]\n",
        "    temp = temp1[i::5]\n",
        "    #len(dataset)\n",
        "    print(dataset.head())\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.plot(dataset['Close'])\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Prices')\n",
        "    plt.title('TCS Closing Prices')\n",
        "\n",
        "    import math\n",
        "    from sklearn.preprocessing import MinMaxScaler \n",
        "    import numpy as np\n",
        "\n",
        "\n",
        "    close = dataset['Close']\n",
        "    arr_close = close.values\n",
        "\n",
        "    scale = MinMaxScaler(feature_range=(0,1))\n",
        "    scaled = scale.fit_transform(arr_close.reshape(-1,1))\n",
        "    #train_data_len = math.ceil(len(arr_close)*0.8)\n",
        "    #train_data_len = math.ceil(len(arr_close)-14)\n",
        "    train_data_len = len(temp)\n",
        "    train_data = scaled[0:train_data_len, :]\n",
        "\n",
        "    print(len(arr_close), train_data_len)\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(60, len(train_data)):\n",
        "        x_train.append(train_data[i-60:i, 0])\n",
        "        y_train.append(train_data[i, 0])\n",
        "        \n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "\n",
        "\n",
        "    test_data = scaled[train_data_len-60: , : ]\n",
        "    x_test = []\n",
        "    y_test = arr_close[train_data_len:]\n",
        "\n",
        "    for i in range(60, len(test_data)):\n",
        "      x_test.append(test_data[i-60:i, 0])\n",
        "\n",
        "    x_test = np.array(x_test)\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "    #print(x_test[0])\n",
        "\n",
        "    '''\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(layers.LSTM(100, return_sequences=False))\n",
        "    model.add(layers.Dense(25))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.summary()\n",
        "    '''\n",
        "\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(layers.Dropout(rate = 0.2))\n",
        "    #model.add(layers.LSTM(100, return_sequences=True))\n",
        "    #model.add(layers.Dropout(rate = 0.2))\n",
        "    #model.add(layers.LSTM(100, return_sequences=True))\n",
        "    #model.add(layers.Dropout(rate = 0.2))\n",
        "    model.add(layers.LSTM(100, return_sequences=False))\n",
        "    model.add(layers.Dropout(rate = 0.2))\n",
        "    model.add(layers.Dense(25))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(x_train, y_train, batch_size= 32, epochs=100)\n",
        "\n",
        "    predictions = model.predict(x_test)\n",
        "    #print(predictions)\n",
        "    predictions = scale.inverse_transform(predictions)\n",
        "\n",
        "    rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "    print(rmse)\n",
        "    rmset.append(rmse)\n",
        "\n",
        "    #print(predictions)\n",
        "\n",
        "    data = dataset.filter(['Close'])\n",
        "    train = data[:train_data_len]\n",
        "    validation = data[train_data_len:]\n",
        "    validation['Predictions'] = predictions\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.title('Model')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Close Price')\n",
        "    plt.plot(train)\n",
        "    plt.plot(validation[['Close', 'Predictions']])\n",
        "    plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    a = []\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "\n",
        "    import pandas\n",
        "    from datetime import date, timedelta\n",
        "\n",
        "    tdata = dataset[len(temp)-1:]\n",
        "    drange = tdata.reset_index()['Date']\n",
        "    #dates2 = dict()\n",
        "    d = str(drange[0].strftime('%Y-%m-%d'))\n",
        "\n",
        "    if (predictions[0][0] > y_train[-1] and y_test[0] > y_train[-1]):\n",
        "      tp+=1\n",
        "      dates.append(d)\n",
        "      #dates2[d] = 1\n",
        "    elif (predictions[0][0] > y_train[-1] and y_test[0] < y_train[-1]):\n",
        "      fp+=1\n",
        "      dates.append(d)\n",
        "      #dates2[d] = 1\n",
        "    elif (predictions[0][0] < y_train[-1] and y_test[0] > y_train[-1]):\n",
        "      fn+=1\n",
        "      #dates2[d] = 0\n",
        "    else:\n",
        "      tn+=1\n",
        "      #dates2[d] = 0\n",
        "\n",
        "    for i in range(1, len(predictions)):\n",
        "      d = str(drange[i].strftime('%Y-%m-%d'))\n",
        "      if (predictions[i][0] > y_test[i-1] and y_test[i] > y_test[i-1]):\n",
        "        tp+=1\n",
        "        dates.append(d)\n",
        "      elif (predictions[i][0] > y_test[i-1] and y_test[i] < y_test[i-1]):\n",
        "        fp+=1\n",
        "        dates.append(d)\n",
        "      elif (predictions[i][0] < y_test[i-1] and y_test[i] > y_test[i-1]):\n",
        "        fn+=1\n",
        "      else:\n",
        "        tn+=1\n",
        "      \n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "      a.append(abs(predictions[i][0] - y_test[i])/y_test[i]*100)\n",
        "    print(max(a), min(a), sum(a)/len(a))\n",
        "    print(tp, fp, fn, tn)\n",
        "    tpg = tpg + tp\n",
        "    fpg = fpg + fp\n",
        "    fng = fng + fn\n",
        "    tng = tng + tn\n",
        "\n",
        "    #print(tp+tn+fp+fn)\n",
        "    #print(len(y_test))\n",
        "    print((tp+tn)/(tp+tn+fn+fp)*100) # accuracy\n",
        "    #print((tp)/(tp+fn)*100) # sensitivity\n",
        "    #print((tp)/(tp+fp)*100) # presicion\n",
        "    #print((tn)/(fp+tn)*100) # specificity\n",
        "    #print( (1 - (tn)/(fp+tn))*100) # 1 - specificity\n",
        "    #print(predictions, y_test)\n",
        "  print(tpg, tng, fng, fpg)\n",
        "  dates.sort()\n",
        "  #print(len(dates))\n",
        "  datef[j] = dates\n",
        "  rmse_dict[j] = rmset\n",
        "  tp_d[j] = tpg\n",
        "  fp_d[j] = fpg\n",
        "  tn_d[j] = tng\n",
        "  fn_d[j] = fng\n",
        "  #print(dates)\n",
        "\n",
        "#print(datef)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsw8Ma_LO4cE"
      },
      "outputs": [],
      "source": [
        "print(rmse_dict)\n",
        "for i in rmse_dict:\n",
        "  rmse_dict[i] = sum(rmse_dict[i])/len(rmse_dict[i])\n",
        "\n",
        "print(rmse_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b2BO-W6p4c8"
      },
      "outputs": [],
      "source": [
        "print(datef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzzS1nc12cd0"
      },
      "outputs": [],
      "source": [
        "print(tp_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxUAd6Tpodov"
      },
      "outputs": [],
      "source": [
        "print(tn_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrJaWbCvofLb"
      },
      "outputs": [],
      "source": [
        "print(fp_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V3ZZ9NaohCZ"
      },
      "outputs": [],
      "source": [
        "print(fn_d)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}