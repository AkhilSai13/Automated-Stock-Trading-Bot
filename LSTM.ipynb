{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhilSai13/Automated-Stock-Trading-Bot/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyn3zoNnqSAa"
      },
      "outputs": [],
      "source": [
        "import yfinance as y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5SEmhaVyxSG"
      },
      "outputs": [],
      "source": [
        "dataset = y.download('TCS.NS', start = '2010-01-01', end = '2014-12-31')\n",
        "dataset2 = y.download('TCS.NS', start = '2015-01-01', end = '2020-01-01')\n",
        "len(dataset)\n",
        "#dataset.head() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl8_MaUnJmVb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 10)) \n",
        "plt.plot(dataset['Close'])\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Prices')\n",
        "plt.title('TCS Closing Prices')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyasSIiXVf_F"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "close = dataset['Close']\n",
        "close2 = dataset2['Close']\n",
        "open = dataset2['Open']\n",
        "arr_open = open.values\n",
        "arr_close2 = close2.values\n",
        "arr_close = close.values\n",
        "arr = list(arr_close) + list(arr_close2)\n",
        "arr = np.array(arr)\n",
        "#print(len(arr))\n",
        "#print(len(arr_close), len(arr_close2))\n",
        "#print(arr_close[0],arr[0], arr[-1], arr_close2[-1])\n",
        "scale = MinMaxScaler(feature_range=(0,1))\n",
        "scaled = scale.fit_transform(arr_close.reshape(-1,1))\n",
        "#scaled2 = scale.fit_transform(arr.reshape(-1,1))\n",
        "#train_data_len = math.ceil(len(arr_close)*0.8)\n",
        "#train_data_len = math.ceil(len(arr_close)-14)\n",
        "train_data_len = len(arr_close)\n",
        "train_data = scaled[0:train_data_len, :]   \n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(30, len(train_data)):\n",
        "    x_train.append(train_data[i-30:i, 0])\n",
        "    y_train.append(train_data[i, 0])\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Poz_wfERPY"
      },
      "outputs": [],
      "source": [
        "test_data = scaled[train_data_len-30: , : ]\n",
        "x_test = []\n",
        "#y_test = arr_close[train_data_len:]\n",
        "\n",
        "#for i in range(14, len(test_data)):\n",
        "x_test.append(test_data[-30: , 0])\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "global_x_test = x_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hasTwrEAMid4"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(layers.LSTM(100, return_sequences=False))\n",
        "model.add(layers.Dense(25))\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvwVXJnYM0uf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(x_train, y_train, batch_size= 1, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwF6miCFM_HE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_array_ops import prevent_gradient_eager_fallback\n",
        "import pandas\n",
        "from datetime import date, timedelta\n",
        "#predictions = model.predict(x_test)\n",
        "#predictions = scale.inverse_transform(predictions)\n",
        "#rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "#rmse\n",
        "#drange = pandas.date_range(date(2015,1,1), date(2020,1,1)-timedelta(days=1),freq='d')\n",
        "drange = dataset2.reset_index()['Date']\n",
        "dates = []\n",
        "dates2 = dict()\n",
        "\n",
        "for i in range(1229):\n",
        "  predictions = []\n",
        "  for j in range(14):\n",
        "    pred = model.predict(np.array(x_test[0][-30:], ndmin = 3))\n",
        "    x_test = np.array(np.append(x_test[0], pred, axis=0), ndmin = 3)\n",
        "    print(scale.inverse_transform(pred))\n",
        "    predictions.append(scale.inverse_transform(pred)[0][0])\n",
        "  \n",
        "  d = str(drange[i].strftime('%Y-%m-%d'))\n",
        "  if(predictions[-1] >= arr_open[i]):\n",
        "    dates.append(d)\n",
        "    dates2[d] = 1\n",
        "  else:\n",
        "    #dates.append(0)\n",
        "    dates2[d] = 0\n",
        "\n",
        "  # train the model with new data\n",
        "  arr_close = np.append(arr_close, [arr[1232 + i]], axis = 0)\n",
        "  scaled = scale.fit_transform(arr_close.reshape(-1,1))\n",
        "  #train_data = np.append(train_data, scaled, axis = 0)\n",
        "  y_train = scaled[1232 + i]\n",
        "  x_train = scaled[1232 + i -30 : 1232 + i]\n",
        "  x_train, y_train = np.array(x_train, ndmin = 3), np.array(y_train)\n",
        "  #x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) \n",
        "  model.fit(x_train, y_train, batch_size= 1, epochs=10)\n",
        "\n",
        "  # add new data to global_x_test\n",
        "  new_data = np.array(y_train, ndmin = 2)\n",
        "  global_x_test = np.array(np.append(global_x_test[0], new_data, axis=0), ndmin = 3)\n",
        "\n",
        "  x_test = global_x_test\n",
        "\n",
        "\n",
        "'''\n",
        "predictions = []\n",
        "for i in range(14):\n",
        "  #np.concatenate(predictions, model.predict(predictions[-14: ]))\n",
        "  pred = model.predict(np.array(x_test[0][-30:], ndmin = 3))\n",
        "  x_test = np.array(np.append(x_test[0], pred, axis=0), ndmin = 3)\n",
        "  print(scale.inverse_transform(pred))\n",
        "  predictions.append(scale.inverse_transform(pred)[0][0])\n",
        "  \n",
        "if(predictions[-1] <= arr_close2[0]):\n",
        "  dates.append(0)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u0jqLyFC2jNH"
      },
      "outputs": [],
      "source": [
        "print(len(dates2))\n",
        "print(len(dates))\n",
        "print(predictions[0])\n",
        "print(arr_close2[-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGmOFTeCUV2KLbn5FIRjcz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}